
Learn about NLTK word_tokenize in the NLTK Book, Chapter 3.
http://www.nltk.org/book/

$ conda activate python35 #virtual-environment

$ python --version
Python 3.5.5 :: Anaconda, Inc.

$ python

>>> import nltk
>>> from nltk import word_tokenize

>>> nltk.download('punkt')
>>> nltk.download('averaged_perceptron_tagger')

>>> text = word_tokenize("This is my own invention")
>>> nltk.pos_tag(text)
[('This', 'DT'), ('is', 'VBZ'), ('my', 'PRP$'), ('own', 'JJ'), ('invention', 'NN')]

>>> exit()

$ conda deactivate #virtual-environment
